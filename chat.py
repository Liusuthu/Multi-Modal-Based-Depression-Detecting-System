import os
from openai import OpenAI
import gradio as gr

OpenAI.api_key = os.getenv("OPENAI_API_KEY")
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)



def predict(message, history):
    history_openai_format = []
    history_openai_format.append({"role": "assistant", "content":"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­å›½å¿ƒç†å’¨è¯¢å¸ˆä¸å¿ƒç†é™ªä¼´å¸ˆï¼Œä½ çš„æ‰€æœ‰å†…å®¹éƒ½éœ€è¦ç”¨ã€ä¸­æ–‡ã€‘å›ç­”ï¼Œä½ å¿…é¡»å¯¹ä½ çš„æ‚£è€…è€å¿ƒï¼Œä½ éœ€è¦ä»¥ã€æœ‹å‹ã€‘çš„èº«ä»½å’Œæ‚£è€…äº¤æµï¼Œè¿™æ„å‘³ç€ä½ éœ€è¦ç”¨æ›´åŠ ã€å£è¯­åŒ–ã€‘çš„æ–‡å­—å›ç­”ï¼Œå¹¶ä¸”ã€ä¸è¦é•¿ç¯‡å¤§è®ºã€‘ï¼Œæ›´ã€ä¸è¦åˆ†ç‚¹ä½œç­”ã€‘ã€‚å¯ä»¥å¶å°”é’ˆå¯¹ç”¨æˆ·çš„å›ç­”è¿›è¡Œã€æé—®ã€‘ï¼Œå¹¶ç»™äºˆå¿…è¦çš„ã€å»ºè®®å’Œå¼•å¯¼ã€‘ã€‚"})
    for human, assistant in history:
        history_openai_format.append({"role": "user", "content": human })
        history_openai_format.append({"role": "assistant", "content":assistant})
    history_openai_format.append({"role": "user", "content": message})
  
    response = client.chat.completions.create(model='gpt-3.5-turbo',
       messages= history_openai_format,
        temperature=1.0,
        stream=True)

    partial_message = ""
    for chunk in response:
        if chunk.choices[0].delta.content is not None:
              partial_message = partial_message + chunk.choices[0].delta.content
              yield partial_message

chat=gr.ChatInterface(
    predict,
    chatbot=gr.Chatbot(
        height=400,
        bubble_full_width=False,
        avatar_images=(os.path.join(os.path.dirname(__file__), "patient_ava.png"), os.path.join(os.path.dirname(__file__), "docter_ava.png")),
        likeable=True,
    ),
    # textbox=gr.Textbox(placeholder="åœ¨æ­¤ä¹¦è¾“å…¥æ¶ˆæ¯...",),
    retry_btn="ğŸ”„é‡æ–°ç”Ÿæˆ",
    undo_btn="â†©ï¸æ’¤å›ä¿¡æ¯",
    clear_btn="ğŸ—‘ï¸æ¸…ç©ºä¿¡æ¯",
    stop_btn="åœæ­¢ç”Ÿæˆ",
    submit_btn="å‘é€",
    
)